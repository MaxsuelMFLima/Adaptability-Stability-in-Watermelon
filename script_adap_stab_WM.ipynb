{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0d165-f356-417f-a881-d44ebc1f58ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import libraries\n",
    "\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd96137-f885-418f-b600-53c12f7c2b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data\n",
    "\n",
    "### Adjust the command according to the name and directory of your data\n",
    "\n",
    "# file_path = '...your directory here.../data.txt' \n",
    "\n",
    "### It's important to check if the decimal place is defined by a \".\" or \",\". \n",
    "### Adjust as needed.\n",
    "df_all = pd.read_csv(file_path, sep='\\t', header=0, decimal='.') \n",
    "\n",
    "\n",
    "### Adjust the entries according to the data or, if you prefer, modify the name of each column. \n",
    "### AMB = environment, GEN = genotype, BLO = block or repetition, PROD = yield.\n",
    "df = df_all[['AMB', 'GEN', 'BLO', 'PROD']]\n",
    "\n",
    "\n",
    "df = df.groupby(['AMB', 'GEN'])[['PROD']].mean().reset_index()\n",
    "\n",
    "### Round the values ​​to two decimal places\n",
    "df = df.round({'PROD': 2})\n",
    "\n",
    "#df.to_csv('genotype_yield.txt', sep='\\t', decimal='.', index=False)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b38cd4-331b-4f20-9820-e3deda6d095d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANOVA\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "df_ANOVA = df_all[['AMB', 'GEN', 'BLO', 'PROD']]\n",
    "df_ANOVA = df_ANOVA.groupby(['AMB', 'GEN', 'BLO'])[['PROD']].mean().reset_index()\n",
    "\n",
    "r = len(df_ANOVA['BLO'].unique())\n",
    "model = ols(\"PROD ~ C(BLO):C(AMB) + C(AMB) + C(GEN) + C(AMB):C(GEN)\", data=df_ANOVA).fit()\n",
    "\n",
    "### Use typ=2 for the average sum of squares\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)  \n",
    "anova_table[\"QM\"] = anova_table[\"sum_sq\"] / anova_table[\"df\"]\n",
    "\n",
    "### # Replace \"PROD\" with your response variable\n",
    "mean_prod = df_ANOVA[\"PROD\"].mean()  \n",
    "\n",
    "### model.mse_resid It directly provides the QMR (root mean square of the residuals).\n",
    "qmr = model.mse_resid  \n",
    "\n",
    "QMR_global = qmr\n",
    "cv = (qmr**0.5 / mean_prod) * 100\n",
    "print(\"\\nMean Squares (MS) per term:\")\n",
    "for term, qm in anova_table[\"QM\"].items():\n",
    "    print(f\"{term}: {qm:.4f}\")\n",
    "\n",
    "print(f\"Coefficient of Variation (CV%): {cv:.2f}\")\n",
    "print(f\"Overall mean: {mean_prod:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfbabbf-8360-4978-ab3f-7f8e98fafb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Frequentist method for determining a priori information\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import time\n",
    "\n",
    "### Assume that df contains the columns 'GEN', 'AMB', and 'PROD'. \n",
    "### Otherwise, adjustments will be necessary.\n",
    "\n",
    "### Classical environmental index for initial impulse U_j\n",
    "env_means = df.groupby('AMB')['PROD'].mean()\n",
    "grand_mean = df['PROD'].mean()\n",
    "U_init = env_means - grand_mean\n",
    "U_values = pd.Series(U_init, name='U')\n",
    "gens = df['GEN'].unique()\n",
    "amb_df = df.groupby('AMB').size() \n",
    "max_iter = 2000\n",
    "tol = 1e-4\n",
    "\n",
    "def regression_step(U_values):\n",
    "    new_params = {}\n",
    "    new_models = {}\n",
    "    for gen in gens:\n",
    "        df_gen = df[df['GEN'] == gen].copy()\n",
    "        df_gen = df_gen.join(U_values, on='AMB')\n",
    "        df_gen['Z'] = df_gen['U'].apply(lambda x: 1 if x <= 0 else 0)\n",
    "        df_gen['ZU'] = df_gen['Z'] * df_gen['U']\n",
    "        df_gen['NZU'] = (1 - df_gen['Z']) * df_gen['U']\n",
    "        \n",
    "        X = sm.add_constant(df_gen[['ZU', 'NZU']])\n",
    "        y = df_gen['PROD']\n",
    "        \n",
    "        model = sm.OLS(y, X).fit()\n",
    "        new_params[gen] = model.params\n",
    "        new_models[gen] = model\n",
    "    return new_params, new_models\n",
    "\n",
    "def update_U(params):\n",
    "    new_U = {}\n",
    "    for amb in amb_df.index:\n",
    "        numerador = 0.0\n",
    "        denominador = 0.0\n",
    "        # Use U_values para determinar Z_j atual\n",
    "        Zj = 1 if U_values[amb] <= 0 else 0\n",
    "        df_amb = df[df['AMB'] == amb]\n",
    "        for gen in gens:\n",
    "            df_g = df_amb[df_amb['GEN'] == gen]\n",
    "            if df_g.empty:\n",
    "                continue\n",
    "            a = params[gen]['const']\n",
    "            b1 = params[gen]['ZU']\n",
    "            b2 = params[gen]['NZU']\n",
    "            b = b1 if Zj == 1 else b2\n",
    "            y = df_g['PROD'].values\n",
    "            numerador += np.sum((y - a) * b)\n",
    "            denominador += np.sum(b**2)\n",
    "        if denominador != 0:\n",
    "            new_U[amb] = numerador / denominador\n",
    "        else:\n",
    "            new_U[amb] = U_values[amb]  \n",
    "    return pd.Series(new_U, name='U')  ### ** It's important to name the series **\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(max_iter):\n",
    "    new_params, new_models = regression_step(U_values)\n",
    "   \n",
    "    new_U = update_U(new_params)\n",
    "    \n",
    "    diff = np.max(np.abs(new_U - U_values))\n",
    "    print(f\"Iter {i+1}, max U change = {diff:.6f}\")\n",
    "    \n",
    "    if diff < tol:\n",
    "        print(\"Convergência atingida.\")\n",
    "        break\n",
    "    \n",
    "    U_values = new_U\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Tempo total: {end_time - start_time:.2f} s\")\n",
    "\n",
    "results = []\n",
    "for gen in gens:\n",
    "    df_gen = df[df['GEN'] == gen].copy()\n",
    "    df_gen = df_gen.join(U_values, on='AMB')\n",
    "    df_gen['Z'] = df_gen['U'].apply(lambda x: 1 if x <= 0 else 0)\n",
    "    df_gen['ZU'] = df_gen['Z'] * df_gen['U']\n",
    "    df_gen['NZU'] = (1 - df_gen['Z']) * df_gen['U']\n",
    "    \n",
    "    X = sm.add_constant(df_gen[['ZU', 'NZU']])\n",
    "    y = df_gen['PROD']\n",
    "    \n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    t_a = model.t_test('const = 0').summary_frame().iloc[0]\n",
    "    t_b10 = model.t_test('ZU = 0').summary_frame().iloc[0]\n",
    "    t_b11 = model.t_test('ZU = 1').summary_frame().iloc[0]\n",
    "    t_b20 = model.t_test('NZU = 0').summary_frame().iloc[0]\n",
    "    t_b21 = model.t_test('NZU = 1').summary_frame().iloc[0]\n",
    "    \n",
    "    t_b1_eq_b2 = model.t_test('ZU - NZU = 0').summary_frame().iloc[0]\n",
    "    f_b1_eq_b2_res = model.f_test('ZU = NZU')\n",
    "    f_stat = f_b1_eq_b2_res.fvalue if hasattr(f_b1_eq_b2_res, 'fvalue') else np.nan\n",
    "    f_pval = f_b1_eq_b2_res.pvalue if hasattr(f_b1_eq_b2_res, 'pvalue') else np.nan\n",
    "    \n",
    "    results.append({\n",
    "        'GEN': gen,\n",
    "        'a_est': model.params['const'],\n",
    "        'a_se': model.bse['const'],\n",
    "        'b1_est': model.params['ZU'],\n",
    "        'b1_se': model.bse['ZU'],\n",
    "        'b2_est': model.params['NZU'],\n",
    "        'b2_se': model.bse['NZU'],\n",
    "        'U_mean': U_values.mean(),\n",
    "        't_a_stat': t_a['t'],\n",
    "        't_a_pval': t_a['P>|t|'],\n",
    "        't_b1_0_stat': t_b10['t'],\n",
    "        't_b1_0_pval': t_b10['P>|t|'],\n",
    "        't_b1_1_stat': t_b11['t'],\n",
    "        't_b1_1_pval': t_b11['P>|t|'],\n",
    "        't_b2_0_stat': t_b20['t'],\n",
    "        't_b2_0_pval': t_b20['P>|t|'],\n",
    "        't_b2_1_stat': t_b21['t'],\n",
    "        't_b2_1_pval': t_b21['P>|t|'],\n",
    "        't_b1_eq_b2_stat': t_b1_eq_b2['t'],\n",
    "        't_b1_eq_b2_pval': t_b1_eq_b2['P>|t|'],\n",
    "        'f_b1_eq_b2_stat': f_stat,\n",
    "        'f_b1_eq_b2_pval': f_pval,\n",
    "    })\n",
    "\n",
    "for res in results:\n",
    "    if res['f_b1_eq_b2_pval'] > 0.05:  # Accept H0 -> use model with common beta\n",
    "        gen = res['GEN']\n",
    "        df_gen = df[df['GEN'] == gen].copy()\n",
    "        df_gen = df_gen.join(U_values, on='AMB')\n",
    "        \n",
    "        # Modelo linear simples com U\n",
    "        X = sm.add_constant(df_gen[['U']])\n",
    "        y = df_gen['PROD']\n",
    "        \n",
    "        model_common = sm.OLS(y, X).fit()\n",
    "        \n",
    "        # Teste t para beta comum = 1\n",
    "        t_beta1 = model_common.t_test('U = 1').summary_frame().iloc[0]\n",
    "\n",
    "        res['beta_comum'] = model_common.params['U']\n",
    "        res['beta_comum_se'] = model_common.bse['U']\n",
    "        res['beta_comum_t'] = model_common.tvalues['U']\n",
    "        res['beta_comum_pval'] = model_common.pvalues['U']\n",
    "        res['t_beta_comum_eq_1_stat'] = t_beta1['t']\n",
    "        res['t_beta_comum_eq_1_pval'] = t_beta1['P>|t|']\n",
    "    else:\n",
    "        res['beta_comum'] = np.nan\n",
    "        res['beta_comum_se'] = np.nan\n",
    "        res['beta_comum_t'] = np.nan\n",
    "        res['beta_comum_pval'] = np.nan\n",
    "        res['t_beta_comum_eq_1_stat'] = np.nan\n",
    "        res['t_beta_comum_eq_1_pval'] = np.nan\n",
    "\n",
    "param_df = pd.DataFrame(results)\n",
    "#param_df.to_csv('estimated_parameters.txt', sep='\\t', decimal='.', index=False)\n",
    "print(param_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab68755-9561-4b34-bf56-f286d388cef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BAYESIAN INFERENCE\n",
    "\n",
    "### Let's divide this into two steps:\n",
    "### 1) considering that all genotypes fit the linear model, i.e., with a common beta)\n",
    "### 2) considering that all genotypes fit the segmented model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082ac61c-56c6-401f-98ec-7867dcf99c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Step 1 --- ###\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ultranest\n",
    "from scipy.stats import norm\n",
    "\n",
    "env_means = df.groupby('AMB')['PROD'].mean()\n",
    "grand_mean = df['PROD'].mean()\n",
    "U_values = env_means - grand_mean  # U(j) = média ambiente - média geral\n",
    "\n",
    "param_df = param_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "def fit_toler_simple_bayes(df_gen, U_values, prior_means, prior_stds):\n",
    "    df_gen = df_gen.copy()\n",
    "    df_gen = df_gen.join(U_values.rename(\"U\"), on='AMB')\n",
    "    y = df_gen['PROD'].values\n",
    "    U = df_gen['U'].values\n",
    "    n = len(y)\n",
    "\n",
    "    param_names = ['a', 'b']\n",
    "\n",
    "    def prior_transform(cube):\n",
    "        u0 = np.clip(cube[0], 1e-6, 1 - 1e-6)\n",
    "        u1 = np.clip(cube[1], 1e-6, 1 - 1e-6)\n",
    "        a = norm.ppf(u0, loc=prior_means['a'], scale=max(prior_stds['a'], 1e-3))\n",
    "        b = norm.ppf(u1, loc=prior_means['b'], scale=max(prior_stds['b'], 1e-3))\n",
    "        return [a, b]\n",
    "\n",
    "    def loglike(params):\n",
    "        a, b = params\n",
    "        mu = a + b * U\n",
    "        residuals = y - mu\n",
    "        sigma = np.std(residuals) if n > 1 else 1.0\n",
    "        if sigma <= 0 or not np.isfinite(sigma):\n",
    "            return -np.inf\n",
    "        return -0.5 * np.sum(np.log(2 * np.pi * sigma**2) + (residuals / sigma) ** 2)\n",
    "\n",
    "    sampler = ultranest.ReactiveNestedSampler(param_names, loglike, prior_transform)\n",
    "    result = sampler.run(min_num_live_points=400, dlogz=0.5, max_ncalls=10000)\n",
    "\n",
    "    samples = result['samples']\n",
    "    means = dict(zip(param_names, samples.mean(axis=0)))\n",
    "    hdi_low = np.percentile(samples, 2.5, axis=0)\n",
    "    hdi_high = np.percentile(samples, 97.5, axis=0)\n",
    "    hdi = dict(zip(param_names, zip(hdi_low, hdi_high)))\n",
    "\n",
    "    return {'means': means, 'hdi': hdi, 'samples': samples}\n",
    "\n",
    "results_toler_simple = {}\n",
    "\n",
    "for gen in df['GEN'].unique():\n",
    "    df_gen = df[df['GEN'] == gen]\n",
    "    row = param_df[param_df['GEN'] == gen].iloc[0]\n",
    "\n",
    "    a_mean = row['a_est'] if np.isfinite(row['a_est']) else 30.0\n",
    "    a_se = row['a_se'] if np.isfinite(row['a_se']) and row['a_se'] > 0 else 5.0\n",
    "    b_mean = row['beta_comum'] if np.isfinite(row['beta_comum']) else 1.0\n",
    "    b_se = row['beta_comum_se'] if np.isfinite(row['beta_comum_se']) and row['beta_comum_se'] > 0 else 1.0\n",
    "\n",
    "    prior_means = {'a': a_mean, 'b': b_mean}\n",
    "    prior_stds = {'a': a_se, 'b': b_se}\n",
    "\n",
    "    print(f\"Running for each genotype {gen}\")\n",
    "    res = fit_toler_simple_bayes(df_gen, U_values, prior_means, prior_stds)\n",
    "    results_toler_simple[gen] = res\n",
    "\n",
    "print(\"\\nResults for beta_common (Bayesian):\")\n",
    "for gen, res in results_toler_simple.items():\n",
    "    m = res['means']\n",
    "    h = res['hdi']\n",
    "    print(f\"Genotype {gen}:\")\n",
    "    print(f\" a = {m['a']:.2f}, HDI = [{h['a'][0]:.2f}, {h['a'][1]:.2f}]\")\n",
    "    print(f\" b = {m['b']:.2f}, HDI = [{h['b'][0]:.2f}, {h['b'][1]:.2f}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b0c29f-0d59-4546-ac40-7385946ec983",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Step 1 --- ###\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "env_means = df.groupby('AMB')['PROD'].mean()\n",
    "grand_mean = df['PROD'].mean()\n",
    "U_values = env_means - grand_mean  # U(j)\n",
    "\n",
    "param_df = param_df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "def fit_toler_simple_bayes_pymc(df_gen, U_values, prior_means, prior_stds):\n",
    "\n",
    "    df_gen = df_gen.copy()\n",
    "    df_gen = df_gen.join(U_values.rename(\"U\"), on='AMB')\n",
    "\n",
    "    y = df_gen['PROD'].values\n",
    "    U = df_gen['U'].values\n",
    "\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        # Priors informativos\n",
    "        a = pm.Normal(\"a\",\n",
    "                      mu=prior_means['a'],\n",
    "                      sigma=max(prior_stds['a'], 1e-3))\n",
    "\n",
    "        b = pm.Normal(\"b\",\n",
    "                      mu=prior_means['b'],\n",
    "                      sigma=max(prior_stds['b'], 1e-3))\n",
    "\n",
    "        sigma = pm.HalfNormal(\"sigma\", sigma=10)\n",
    "\n",
    "        # Modelo linear\n",
    "        mu = a + b * U\n",
    "\n",
    "        # Likelihood\n",
    "        y_obs = pm.Normal(\"y_obs\", mu=mu, sigma=sigma, observed=y)\n",
    "\n",
    "        trace = pm.sample(\n",
    "            draws=4000,\n",
    "            tune=2000,\n",
    "            target_accept=0.9,\n",
    "            cores=4,\n",
    "            return_inferencedata=True,\n",
    "            progressbar=True\n",
    "        )\n",
    "\n",
    "    summary = az.summary(trace, hdi_prob=0.95)\n",
    "\n",
    "    means = {\n",
    "        'a': summary.loc['a', 'mean'],\n",
    "        'b': summary.loc['b', 'mean']\n",
    "    }\n",
    "\n",
    "    hdi = {\n",
    "        'a': (summary.loc['a', 'hdi_2.5%'], summary.loc['a', 'hdi_97.5%']),\n",
    "        'b': (summary.loc['b', 'hdi_2.5%'], summary.loc['b', 'hdi_97.5%'])\n",
    "    }\n",
    "\n",
    "    samples = trace.posterior\n",
    "\n",
    "    return {'means': means, 'hdi': hdi, 'trace': trace, 'samples': samples}\n",
    "\n",
    "\n",
    "# =============================\n",
    "# Loop por genótipo\n",
    "# =============================\n",
    "\n",
    "results_toler_simple = {}\n",
    "\n",
    "for gen in df['GEN'].unique():\n",
    "\n",
    "    df_gen = df[df['GEN'] == gen]\n",
    "    row = param_df[param_df['GEN'] == gen].iloc[0]\n",
    "\n",
    "    a_mean = row['a_est'] if np.isfinite(row['a_est']) else 30.0\n",
    "    a_se = row['a_se'] if np.isfinite(row['a_se']) and row['a_se'] > 0 else 5.0\n",
    "\n",
    "    b_mean = row['beta_comum'] if np.isfinite(row['beta_comum']) else 1.0\n",
    "    b_se = row['beta_comum_se'] if np.isfinite(row['beta_comum_se']) and row['beta_comum_se'] > 0 else 1.0\n",
    "\n",
    "    prior_means = {'a': a_mean, 'b': b_mean}\n",
    "    prior_stds = {'a': a_se, 'b': b_se}\n",
    "\n",
    "    print(f\"Running for genotype {gen}\")\n",
    "\n",
    "    res = fit_toler_simple_bayes_pymc(\n",
    "        df_gen,\n",
    "        U_values,\n",
    "        prior_means,\n",
    "        prior_stds\n",
    "    )\n",
    "\n",
    "    results_toler_simple[gen] = res\n",
    "\n",
    "\n",
    "# =============================\n",
    "# Results\n",
    "# =============================\n",
    "\n",
    "print(\"\\nResults for beta_common (Bayesian - PyMC):\")\n",
    "\n",
    "for gen, res in results_toler_simple.items():\n",
    "    m = res['means']\n",
    "    h = res['hdi']\n",
    "\n",
    "    print(f\"Genotype {gen}:\")\n",
    "    print(f\" a = {m['a']:.2f}, HDI = [{h['a'][0]:.2f}, {h['a'][1]:.2f}]\")\n",
    "    print(f\" b = {m['b']:.2f}, HDI = [{h['b'][0]:.2f}, {h['b'][1]:.2f}]\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67800b9c-a357-44a3-802d-cb53cc838c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "### --- Step 2 --- ###\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ====================================================\n",
    "# CHECK IF ANOVA RESULTS EXIST\n",
    "# ====================================================\n",
    "if 'QMR_global' not in globals():\n",
    "    raise ValueError(\"QMR_global not found. Run ANOVA cell first.\")\n",
    "\n",
    "if 'r' not in globals():\n",
    "    raise ValueError(\"Number of replications (r) not found. Run ANOVA cell first.\")\n",
    "\n",
    "# ====================================================\n",
    "# CONFIGURATIONS\n",
    "# ====================================================\n",
    "output_dir = 'bayesian_adaptability_toler_step2'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ====================================================\n",
    "# PREPROCESSING (Environmental Index μj)\n",
    "# ====================================================\n",
    "df_ambiental = (\n",
    "    df.groupby('AMB', as_index=False)\n",
    "      .agg({'PROD': 'mean'})\n",
    "      .rename(columns={'PROD': 'Ij'})\n",
    ")\n",
    "\n",
    "I_mean = df_ambiental['Ij'].mean()\n",
    "df_ambiental['mu_j'] = df_ambiental['Ij'] - I_mean\n",
    "\n",
    "# Atribuição segura (sem merge)\n",
    "df['mu_j'] = df['AMB'].map(\n",
    "    df_ambiental.set_index('AMB')['mu_j']\n",
    ")\n",
    "\n",
    "# ====================================================\n",
    "# BAYESIAN MODELING (TOLER, 1998)\n",
    "# ====================================================\n",
    "results = {}\n",
    "\n",
    "for genotype in df['GEN'].unique():\n",
    "\n",
    "    df_genotype = df[df['GEN'] == genotype]\n",
    "    X = df_genotype['mu_j'].values\n",
    "    y = df_genotype['PROD'].values\n",
    "\n",
    "    with pm.Model() as model:\n",
    "\n",
    "        alpha = pm.Normal(\"alpha\", mu=np.mean(y), sigma=25)\n",
    "        beta1 = pm.Normal(\"beta1\", mu=1, sigma=5)\n",
    "        beta2 = pm.Normal(\"beta2\", mu=1, sigma=5)\n",
    "        sigma = pm.HalfNormal(\"sigma\", sigma=5)\n",
    "\n",
    "        mu = alpha + beta1 * X * (X <= 0) + beta2 * X * (X > 0)\n",
    "\n",
    "        Y_obs = pm.Normal(\"Y_obs\", mu=mu, sigma=sigma, observed=y)\n",
    "\n",
    "        trace = pm.sample(\n",
    "            draws=4000,\n",
    "            tune=2000,\n",
    "            target_accept=0.9,\n",
    "            cores=4,\n",
    "            return_inferencedata=True,\n",
    "            progressbar=True\n",
    "        )\n",
    "\n",
    "    # ====================================================\n",
    "    # Posterior summaries\n",
    "    # ====================================================\n",
    "    summary = az.summary(trace, hdi_prob=0.95)\n",
    "\n",
    "    beta1_median = np.median(trace.posterior['beta1'].values)\n",
    "    beta2_median = np.median(trace.posterior['beta2'].values)\n",
    "    alpha_median = np.median(trace.posterior['alpha'].values)\n",
    "\n",
    "    hdi_beta1 = (\n",
    "        summary.loc['beta1', 'hdi_2.5%'],\n",
    "        summary.loc['beta1', 'hdi_97.5%']\n",
    "    )\n",
    "\n",
    "    hdi_beta2 = (\n",
    "        summary.loc['beta2', 'hdi_2.5%'],\n",
    "        summary.loc['beta2', 'hdi_97.5%']\n",
    "    )\n",
    "\n",
    "    # ====================================================\n",
    "    # Stability (S²d)\n",
    "    # ====================================================\n",
    "    alpha_samples = trace.posterior['alpha'].values.reshape(-1)\n",
    "    beta1_samples = trace.posterior['beta1'].values.reshape(-1)\n",
    "    beta2_samples = trace.posterior['beta2'].values.reshape(-1)\n",
    "\n",
    "    y_preds = np.array([\n",
    "        a + b1 * X * (X <= 0) + b2 * X * (X > 0)\n",
    "        for a, b1, b2 in zip(alpha_samples, beta1_samples, beta2_samples)\n",
    "    ])\n",
    "\n",
    "    y_median = np.median(y_preds, axis=0)\n",
    "\n",
    "    # n - 3 parameters (alpha, beta1, beta2)\n",
    "    QMD_i = ((y - y_median) ** 2).sum() / (len(y) - 3)\n",
    "\n",
    "    S2d = (QMD_i * r - QMR_global) / r\n",
    "\n",
    "    # ====================================================\n",
    "    # Store results\n",
    "    # ====================================================\n",
    "    results[genotype] = {\n",
    "        'alpha_median': alpha_median,\n",
    "        'beta1_median': beta1_median,\n",
    "        'beta2_median': beta2_median,\n",
    "        'beta1_HDI_low': hdi_beta1[0],\n",
    "        'beta1_HDI_high': hdi_beta1[1],\n",
    "        'beta2_HDI_low': hdi_beta2[0],\n",
    "        'beta2_HDI_high': hdi_beta2[1],\n",
    "        'S2d': S2d\n",
    "    }\n",
    "\n",
    "# ====================================================\n",
    "# SAVE RESULTS\n",
    "# ====================================================\n",
    "results_df = pd.DataFrame.from_dict(results, orient='index')\n",
    "results_df.to_csv(\n",
    "    os.path.join(output_dir, 'bayesian_results.txt'),\n",
    "    index=True,\n",
    "    sep=\"\\t\",\n",
    "    decimal=\",\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
